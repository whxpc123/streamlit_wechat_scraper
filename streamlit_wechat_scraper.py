import time
import pandas as pd
import streamlit as st
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from io import BytesIO
import base64
import requests
import os

# Streamlit é¡µé¢é…ç½®
st.title('WeChat Article Scraper')
keyword = st.text_input('Enter search keyword', 'AIç»˜ç”»')
num_pages = st.number_input('Enter number of pages to scrape', min_value=1, max_value=20, value=5)
start_button = st.button('Start Scraping')

class DownloadException(Exception):
    pass

def download_image(img_url, image_count):
    try:
        # æ£€æŸ¥æ˜¯å¦æ˜¯base64ç¼–ç çš„å›¾ç‰‡
        if img_url.startswith('data:image'):
            # æå–base64æ•°æ®
            base64_data = img_url.split(',')[1]
            img_data = base64.b64decode(base64_data)
            # ä¿å­˜å›¾ç‰‡
            with open(f"AIGC/{image_count}.jpg", "wb") as file:
                file.write(img_data)
        else:
            # ä¸‹è½½æ™®é€šå›¾ç‰‡
            response = requests.get(img_url, timeout=10)
            if response.status_code == 200:
                img_data = response.content
                # éªŒè¯å›¾ç‰‡æ•°æ®ï¼ˆä½¿ç”¨å¸¸è§çš„å›¾ç‰‡æ ¼å¼è¿›è¡ŒéªŒè¯ï¼‰
                if not img_data.startswith(b'\xff\xd8') and not img_data.endswith(b'\xff\xd9') and \
                        not img_data.startswith(b'\x89PNG') and not img_data.endswith(b'IEND\xaeB`\x82'):
                    raise DownloadException("Invalid image data")
                # ä¿å­˜å›¾ç‰‡
                with open(f"AIGC/{image_count}.jpg", "wb") as file:
                    file.write(img_data)
            else:
                raise DownloadException(f"Failed to download image {image_count}: HTTP {response.status_code}")
    except Exception as e:
        with open("error_log.txt", "a") as log_file:
            log_file.write(f"Failed to download image {image_count}: {str(e)}\n")
        raise DownloadException(f"Failed to download image {image_count}: {str(e)}")

if start_button:
    try:
        # åˆå§‹åŒ–WebDriver
        options = webdriver.ChromeOptions()
        options.add_argument('--headless')  # æ— å¤´æ¨¡å¼ï¼Œä¸æ‰“å¼€æµè§ˆå™¨çª—å£
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

        # ç›®æ ‡ç½‘å€
        url = "https://weixin.sogou.com/"

        # æ‰“å¼€ç›®æ ‡ç½‘å€
        driver.get(url)
        time.sleep(2)

        # è¾“å…¥å…³é”®å­—
        search_box = driver.find_element(By.ID, 'query')
        search_box.send_keys(keyword)
        search_box.send_keys(Keys.RETURN)

        # ç­‰å¾…æœç´¢ç»“æœåŠ è½½
        time.sleep(5)

        # åˆå§‹åŒ–å­˜å‚¨æ•°æ®çš„åˆ—è¡¨
        data = []

        # çˆ¬å–æŒ‡å®šé¡µæ•°çš„æ•°æ®
        for page in range(1, num_pages + 1):
            try:
                articles = WebDriverWait(driver, 10).until(
                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, 'div.txt-box'))
                )

                for index, article in enumerate(articles):
                    try:
                        st.write(f"Processing article {index + 1} on page {page}")
                        title_element = article.find_element(By.CSS_SELECTOR, 'h3')
                        title = title_element.text
                        link = title_element.find_element(By.TAG_NAME, 'a').get_attribute('href')
                        summary = article.find_element(By.CSS_SELECTOR, 'p.txt-info').text

                        # æœ‰äº›æ–‡ç« å¯èƒ½æ²¡æœ‰æ¥æºä¿¡æ¯ï¼Œéœ€è¦è¿›è¡Œæ£€æŸ¥
                        source_element = article.find_elements(By.CSS_SELECTOR, 'div.s-p a')
                        source = source_element[0].text if source_element else 'Unknown'

                        data.append({
                            'Title': title,
                            'Summary': summary,
                            'Link': link,
                            'Source': source
                        })
                    except Exception as e:
                        st.write(f"Error extracting article {index + 1} on page {page}: {e}")
            except Exception as e:
                st.write(f"Error finding articles on page {page}: {e}")
                break

            # ç¿»é¡µ
            if page < num_pages:
                try:
                    next_button = WebDriverWait(driver, 10).until(
                        EC.element_to_be_clickable((By.LINK_TEXT, 'ä¸‹ä¸€é¡µ'))
                    )
                    next_button.click()
                    time.sleep(5)
                except Exception as e:
                    st.write(f"Error clicking next page: {e}")
                    break

        # å…³é—­æµè§ˆå™¨
        driver.quit()

        # ä¿å­˜æ•°æ®åˆ°Excelæ–‡ä»¶
        current_time = time.strftime("%Y%m%d%H%M%S")
        file_name = f"AI_å¾®ä¿¡_{current_time}.xlsx"
        df = pd.DataFrame(data)

        # å°† DataFrame ä¿å­˜åˆ° BytesIO å¯¹è±¡ä¸­
        towrite = BytesIO()
        df.to_excel(towrite, index=False, engine='openpyxl')
        towrite.seek(0)

        # æä¾›æ–‡ä»¶ä¸‹è½½é“¾æ¥
        st.download_button(label='ğŸ“¥ Download Excel File',
                           data=towrite,
                           file_name=file_name,
                           mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
    except Exception as e:
        st.error(f"An error occurred: {e}")
